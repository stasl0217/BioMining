# coding: utf-8

"""
== Notions
1. UMLS: Unified Medical Language System (https://www.nlm.nih.gov/research/umls/)
2. CUI: Concept Unique Identifier in UMLS. 'C' followed by 7 digits.

== Input files
XML generated by cTakes (descriptor: AggregatePlaintextFastUMLSProcessor.xml)

== Output files
1. type.csv
    typeID description
    e.g.
    0   Medication
2. concepts.csv:
    CUI    preferred text
3. itemsets.csv:
    Concepts in one sentence form one itemset.
    File format:
    CUI1    CUI2    0CUI3 ('0' before 'C' for negated concepts)
    e.g.:
    C0277785	C1261287
    C0231683	0C0028778	C0021107
4. itemsets_text.csv
    for debugging

== Author
Shirley Chen (shirleychen@cs.ucla.edu)

== Last updated
Aug 16, 2017

"""

try:
    import xml.etree.cElementTree as ET
except ImportError:
    import xml.etree.ElementTree as ET
import os
from os import listdir
from os.path import isfile, join
from UmlsConcept import UmlsConcept
from ConceptMention import ConceptMention
from Sentence import Sentence
import traceback  # for exception
import csv
import time

os.chdir(r'C:\Users\sinte\LULU\lab\biomining')
# ** GLOBAL VALUES IN THIS MODULE **
_xmldir = r'.\xml'  # '.\xml'
_outdir = r'.\itemsets'
_result_dir = r'.\result_para'

_files = [f for f in listdir(_xmldir) if isfile(join(_xmldir, f))]

# typeID = index
_types = ['org.apache.ctakes.typesystem.type.textsem.MedicationMention',
          'org.apache.ctakes.typesystem.type.textsem.DiseaseDisorderMention',
          'org.apache.ctakes.typesystem.type.textsem.ProcedureMention',
          'org.apache.ctakes.typesystem.type.textsem.SignSymptomMention',
          'org.apache.ctakes.typesystem.type.textsem.AnatomicalSiteMention']
_types_txt = ['Medication', 'Disease/Disorder', 'Procedure', 'Sign/Symptom', 'Anatomical site']
_N = len(_types)
# print type information
file1 = 'types.csv'
with open(join(_result_dir, file1), 'w') as  f1:
    for i in range(len(_types_txt)):
        f1.write('%d\t%s\n' % (i, _types_txt[i]))


def scan_FSArrays(tree):
    '''
    scan the whole XML element tree for ONCE,
    and save all FSArrays in a dictionary.
    :param tree: root of XML element tree
    :return: { FSArray_id: [id1, id2, ...] }
    '''
    FSArrays = {}
    for FSArray in tree.iter(tag='uima.cas.FSArray'):
        FSArray_id = FSArray.attrib['_id']
        ids = []
        for child in FSArray:
            ids.append(child.text)
        FSArrays[FSArray_id] = ids
    return FSArrays


def scan_UmlsConcepts(tree):
    """
    scan the whole XML element tree for ONCE,
    and save all FSArrays in a dictionary.
    :param tree: root of XML element tree
    :return concepts: = { id : UmlsConcept(CUI, preferred_text)}
    :raise KeyError

    """
    concepts = {}  # all UmlsConcepts listed in the XML document
    for ccpt in tree.iter(tag='org.apache.ctakes.typesystem.type.refsem.UmlsConcept'):
        try:
            id = ccpt.attrib['_id']
            concepts[id] = UmlsConcept(ccpt.attrib['cui'], ccpt.attrib['preferredText'])
        except KeyError as e:
            print 'KeyError when analysing the UmlsConcept elements'
            print repr(e)

    return concepts


def scan_sentence_info(tree):
    """
        scan the whole XML element tree for ONCE,
        and save the sentence break information.
        tag: org.apache.ctakes.typesystem.type.textspan.Sentence
        For every sentence, get its id and beginning/ending position.

        NOTE:
        here we assume @sentences(list) is naturally ordered by id(sentenceNumber)
        because they are read in sequence from XML.
        However, if there are multiple threads or other cases when the assumption cannot hold,
        extra SORTING is required here

        :param root: root of XML element tree
        :return: [ Sentence(id, begin, end) objects ...]  naturally ordered by id (reading in sequence from XML)
    """
    sentences = []  # Sentence (id, begin, end)
    for el in tree.iter(tag='org.apache.ctakes.typesystem.type.textspan.Sentence'):
        id = el.attrib['sentenceNumber']  # not '_id', which indicates element ids in this XML document
        begin = int(el.attrib['begin'])
        end = int(el.attrib['end'])
        sentences.append(Sentence(id, begin, end))  # tuple (immutable)
    return sentences


def scan_paragraphs(tree):
    """
    scan the whole XML element tree for ONCE,
    and get the newline token information.
    tag: org.apache.ctakes.typesystem.type.syntax.NewlineToken
    e.g.:
    <org.apache.ctakes.typesystem.type.syntax.NewlineToken
        _indexed="1" _id="357" _ref_sofa="3" b
        egin="11" end="13" tokenNumber="1"/>

    For every newtoken line, get its id and BEGIN as the paragraph break position.
    Consider from [this BEGIN, next BEGIN) as one pargraph.

    NOTE:
    here we assume paragprah_breaks are naturally sorted
    because they are read in sequence from XML.
    However, if there are multiple threads or other cases when the assumption cannot hold,
    extra SORTING is required here

    :param root: root of XML element tree
    :return: [ positions ...]
    """
    paragraph_breaks = [0]  # [ tuple (id, begin), naturally sorted ]
    for el in tree.iter(tag='org.apache.ctakes.typesystem.type.syntax.NewlineToken'):
        # NOTE: tokenNumber is not consecutive
        # NOTE: NOT start from ZERO!
        position = int(el.attrib['begin'])  # new line begin as paragraph break position
        paragraph_breaks.append(position)  # tuple (immutable)
    return paragraph_breaks


def extract_concept(ccptmention_dict, FSArrays, concepts, sentence_list, paragraph_breaks):
    """
    :param ccptmention_dict:
    XML attributes stored in a dict.
    This element MUST be an Named Entity mention element whose tag is in types.

    An example of the original XML element content
    (input is its attributes):

    <org.apache.ctakes.typesystem.type.textsem.MedicationMention _indexed="1"
        _id="2608" _ref_sofa="3" begin="337" end="344" id="16"
        _ref_ontologyConceptArr="2602" typeID="1" segmentID="SIMPLE_SEGMENT"
        discoveryTechnique="1" confidence="0.22500001"
        polarity="1" uncertainty="0" conditional="false" generic="false"
        subject="patient" historyOf="0" _ref_medicationFrequency="3744"
        _ref_medicationStatusChange="3711" _ref_medicationStrength="3778"
        _ref_startDate="3827"/>

    :return: ConceptMention(mention_id, type_id, begin, end, umls, sentence_list, paragraph_breaks, negated)
    :raise:
    KeyError, IndexError
    """
    try:
        mention_id = ccptmention_dict['_id']
        type_id = int(ccptmention_dict['typeID'])
        begin = int(ccptmention_dict['begin'])  # beginning position of the phrase in the original text
        end = int(ccptmention_dict['end'])
        FSArray_id = ccptmention_dict['_ref_ontologyConceptArr']
        polarity = ccptmention_dict['polarity']
        negated = True if polarity == '-1' else False

        # there may be multiple UmlsConcept ids in one FSArray
        # However, in this case, they should all point to ONE entity in UMLS
        # with different code in different schemas but the same CUI
        umls_ids = FSArrays[FSArray_id]  # list
        if len(umls_ids) > 0:
            umls_id = umls_ids[0]
            umls = concepts[umls_id]  # UmlsConcept object
            # last row may raise KeyError (if concepts passed in are not right)
            concept_mention = ConceptMention(mention_id, type_id, begin, end, umls, sentence_list, paragraph_breaks,
                                             negated)
            return concept_mention

        else:
            # normally there shouldn't be an empty FSArray
            raise IndexError('empty FSArray:' + str(FSArray_id))

    except KeyError as e:
        print 'Problem with attribute: ', e
        print ccptmention_dict
        print 'trouble when trying to extract concept from the concept-mentioning element. This element will be ignored'


def find_itemsets(concept_mentions, by_paragraph=False):
    """
    All concepts in one sentence(default) or paragraph form an itemset
    :param concept_mentions: [ ConceptMention objects ]
    :return: { sentence Number : [ConceptMention objects] }
    """
    itemsets = {}  # { sentence Number : ConceptMention object}
    for cm in concept_mentions:
        if by_paragraph:
            unit_id = cm.paragraph
        else:
            unit_id = cm.sentence
        if itemsets.has_key(unit_id):
            itemsets[unit_id].append(cm)
        else:
            itemsets[unit_id] = [cm]
    return itemsets


def save_concepts_text(dir0, concepts):
    """
    APPEND Umls concepts extracted from the current XML
    to a csv file (delimiter: \t)
     (using python csv module)

    NOTE: there may be REPLICATIONS in the final file

    File format:
    CUI    preferred text

    e.g.:
    C0007226    Cardiovascular system

    :param dir0: where the file is
    :param concepts: { id : UmlsConcept object }
    :return:
    :raise: IOError, UnicodeEncodeError
    """
    filename = 'concepts.csv'
    try:
        with open(join(dir0, filename), 'a') as csvfile:
            ccwriter = csv.writer(csvfile, delimiter='\t',
                                  quotechar='|', quoting=csv.QUOTE_MINIMAL)
            for key, value in concepts.items():
                umls = value
                CUI = umls.CUI
                text = umls.preferred_text
                ccwriter.writerow([CUI, text])
    except IOError as e:
        print(repr(e))
        traceback.print_exc()
    except UnicodeEncodeError as ue:
        print(repr(ue))
        traceback.print_exc()


def save_concepts_type(dir0, concept_mentions):
    """
    APPEND Umls concepts and its type, which is defined in cTakes instead of UMLS,
        to a csv file (delimiter: \t)
     (using python csv module)
     NOTE: there may be REPLICATIONS in the file. It should be read into a dict later.

    File format:
    CUI    typeID

    e.g.:
    C0007226    1


    :param dir0: where the file is
    :param concept_mentions: [ ConceptMention objects (with type information)]
    :return:
    """

    file2='concept_types.csv'

    concept_type={}  # {CUI: typeID}
    for cm in concept_mentions:
        CUI=cm.umls.CUI
        typeID=cm.typeID
        concept_type[CUI]=typeID
    # print dict
    try:
        with open(join(dir0, file2), 'a') as csvfile:
            ccwriter = csv.writer(csvfile, delimiter='\t',
                                  quotechar='|', quoting=csv.QUOTE_MINIMAL)
            for cm in concept_mentions:
                CUI=cm.umls.CUI
                typeID=cm.typeID
                ccwriter.writerow([CUI, typeID])
    except IOError as e:
        print(repr(e))
        traceback.print_exc()
    except UnicodeEncodeError as ue:
        print(repr(ue))
        traceback.print_exc()


def save_itemsets(dir0, itemsets):
    """
    APPEND itemsets extracted from the current XML
    to a csv file (delimiter: \t)

    File format:
    CUI1    CUI2    0CUI3 ('0' before 'C' for negated concepts)
    ...

    e.g.:
    C0007226    C0057671
    C0034665    0C0671970    C0050451

    :param dir0: where the file is
    :param itemsets: { sentence Number : [ ConceptMention objects ] }
    :return:
    :raise: IOError, UnicodeEncodeError
    """
    filename = 'itemsets.csv'
    try:
        with open(join(dir0, filename), 'a') as fout:
            for key, value in itemsets.items():
                concept_mentions = value
                for cm in concept_mentions:
                    CUI = cm.umls.CUI
                    if cm.negation:
                        CUI = '0' + CUI  # '0' as a sign for negation
                    fout.write(CUI + '\t')
                fout.write('\n')
    except IOError as ie:
        print(repr(ie))
        traceback.print_exc()
    except UnicodeEncodeError as ue:
        print(repr(ue))
        traceback.print_exc()


def save_itemsets_text(dir0, itemsets):
    """
    APPEND the text form of itemsets (preferred text of all concepts)
    to a csv file (delimiter: ; )
    Use '[negated]' annotation for negated concepts.

    e.g.:
    Left ventricular structure ; Heart Ventricle ;
    Dilated [negated]; Implantation procedure ;

    :param dir0: where the file is
    :param itemsets: { sentence Number : [ ConceptMention objects ] }
    :return:
    :raise: IOError, UncodeEncodeError
    """
    filename = 'itemsets_text.csv'
    try:
        with open(join(dir0, filename), 'a') as fout:
            for key, value in itemsets.items():
                concept_mentions = value
                for cm in concept_mentions:
                    fout.write(cm.text() + '; ')
                fout.write('\n')
    except IOError as e:
        print(repr(e))
        traceback.print_exc()
    except UnicodeEncodeError as ue:
        print(repr(ue))
        traceback.print_exc()


def save_same_source_concepts(concept_mentions):
    """
    Find extracted concepts from the same text
    So they cannot appear at the same time in one itemset
    :param concept_mentions: [ConceptMention objects]
    :return: [ [cm1, cm2], [cm1, cm3] (in pairs) ... ]

    file output:
    (delimiter='\t')
    #TODO: finish document

    For CUI1, CUI2, CUI3
    CUI1    CUI2 (sequence doesn't matter)
    CUI1    CUI3
    CUI2    CUI3

    """
    f1 = 'equa_concepts.csv'
    f2 = 'equa_concepts_text.csv'
    ssc = []
    for cm1 in concept_mentions:
        for cm2 in concept_mentions:
            if cm1.id != cm2.id:
                if not (cm1.begin > cm2.end or cm2.begin > cm1.end):  # overlapping
                    ssc.append([cm1, cm2])
    try:
        with open(join(_result_dir, f1), 'a') as fout1:
            with open(join(_result_dir, f2), 'a') as fout2:
                for pair in ssc:
                    fout1.write(pair[0].umls.CUI + '\t' + pair[1].umls.CUI + '\n')
                    fout2.write(pair[0].umls.preferred_text + '\t' + pair[1].umls.preferred_text + '\n')
    except UnicodeEncodeError as ue:
        print(repr(ue))
        traceback.print_exc()


def main():
    for fname in _files:

        f = join(_xmldir, fname)
        print f

        try:
            # create an element tree for this XML file
            tree = ET.ElementTree(file=f)
            root = tree.getroot()  # get the root element as Element object
        except Exception:
            print 'Error when trying to parse XML'
            print 'filename: ', f

        # scan for elements
        FSArrays = scan_FSArrays(tree)
        umls_concepts = scan_UmlsConcepts(tree)
        sentence_list = scan_sentence_info(tree)  # [ tuple (id1, begin1, end1) ...]
        paragraph_breaks = scan_paragraphs(tree)

        # save UMLS concepts info
        save_concepts_text(_result_dir, umls_concepts)

        concept_mentions = []  # [ConceptMention objects]

        # CORE PART
        # extract all Umls Concept from Named Entity (concept) mentions
        for child in root:
            tag = child.tag
            for typeID in range(0, _N):
                if tag == _types[typeID]:
                    # found the Named Entity (concept) mention element
                    attributes = child.attrib  # XML content (dictionary)
                    mention = extract_concept(attributes, FSArrays, umls_concepts,
                                              sentence_list, paragraph_breaks)  # UmlsConcept (with position info)
                    if mention is not None:
                        # mention.show()
                        concept_mentions.append(mention)
        save_concepts_type(_result_dir,concept_mentions)

        itemsets = find_itemsets(concept_mentions, by_paragraph=True)
        save_same_source_concepts(concept_mentions)

        # write to file
        save_itemsets(_result_dir, itemsets)
        save_itemsets_text(_result_dir, itemsets)


if __name__ == "__main__":
    start_time = time.time()
    main()
    print 'FINISHED'
    print '%d files' % len(_files)
    print 'seconds:', str(time.time() - start_time)
